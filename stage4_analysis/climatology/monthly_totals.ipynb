{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "import netCDF4\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "#######################\n",
    "\n",
    "def extract_events1(p_data):\n",
    "    def storm_def():\n",
    "        def check_mits(mit):\n",
    "            idx = (bin_events  <=-mit)*(bin_events<0)\n",
    "            dry_periods = bin_events[idx]*-1\n",
    "            return np.array([mit, np.std(dry_periods[1:]) / np.mean(dry_periods[1:]),\n",
    "                                np.int32(np.mean(dry_periods[1:]))])\n",
    "\n",
    "        v = (p_data==0)*1\n",
    "        n = v==0\n",
    "        a = ~n\n",
    "        c = np.cumsum(a)\n",
    "        d = np.diff(np.append([0.], c[n]))\n",
    "        v[n] = -d\n",
    "        dry_vec = np.cumsum(v)\n",
    "        bin_events = np.append([1], np.diff(dry_vec))\n",
    "\n",
    "        \n",
    "        mit_dry = []\n",
    "        for mit in mit_list:\n",
    "            _mit = check_mits(mit)\n",
    "            mit_dry.append(_mit)\n",
    "            if ((_mit[1]<1.0) & (len(mit_dry)>1)):\n",
    "                break    # condition satisfied\n",
    "        mit_dry = np.array(mit_dry)\n",
    "        min_mit = calc_min_mit(mit_dry)\n",
    "        \n",
    "        idx = (bin_events  <= -min_mit) * (bin_events < 0)\n",
    "        dry_periods = bin_events[idx]*-1\n",
    "        date_idx = np.where(idx[1:])[0]\n",
    "        event_durations = date_idx[1:] -dry_periods[1:] - date_idx[0:-1]\n",
    "        event_indices = date_idx[0:-1] + event_durations\n",
    "        n_events = len(event_durations)\n",
    "        # storm_def_new(data, mit)\n",
    "\n",
    "        p_totals = [0]*n_events\n",
    "        for i in range(n_events):\n",
    "            p_totals[i] = np.sum(p_data[date_idx[i]:event_indices[i]+1])\n",
    "\n",
    "        \n",
    "        # summary = pd.DataFrame({'dt':dt_vec[date_idx[1:]], 't0':event_durations, 'tb':dry_periods[0:-1], 'intnesity':p_totals/event_durations})\n",
    "        summary = [dt_vec[date_idx[1:]], event_durations, dry_periods[0:-1], p_totals/event_durations]\n",
    "        return min_mit, summary\n",
    "        # return np.array([min_mit, np.std(dry_periods[1:]) / np.mean(dry_periods[1:]), np.int32(np.mean(dry_periods[1:]))])\n",
    "\n",
    "    #######################\n",
    "\n",
    "\n",
    "    def calc_min_mit(p_events):\n",
    "        idx, = np.where((np.diff(np.sign(p_events[:,1]-1)) != 0)*1==1)\n",
    "        if len(idx)==0:\n",
    "            a = np.abs(p_events[:,1]-1)\n",
    "            idx, = np.where(a == a.min())\n",
    "            return p_events[:,0][idx][0]\n",
    "        return (p_events[:,0][idx][0]+p_events[:,0][idx+1][0])/2.0\n",
    "\n",
    "    #######################\n",
    "\n",
    "    result = np.empty((1,1), dtype=object)   \n",
    "    n_data = len(p_data)\n",
    "    # event_metrics = get_events(p_data, set_min_mit)\n",
    "    # %timeit np.sum(p_data < 0)\n",
    "    pos_idx = np.sum((p_data>=0) & (p_data<65535))\n",
    "\n",
    "    # if float(np.sum(neg_idx)/n_data)<0.1:\n",
    "    #     print('No data 1', float(np.sum(p_data < 0)/n_data))\n",
    "    # p_data[p_data<0.5] = 0\n",
    "        \n",
    "    if (float(np.sum(pos_idx)/n_data)==0):\n",
    "        result = np.array([np.nan,np.nan,np.nan])\n",
    "        print('No data 2')\n",
    "    else:\n",
    "        # try:\n",
    "        event_metrics = storm_def()\n",
    "        result = event_metrics\n",
    "        # except:\n",
    "            # result = np.array([np.nan,np.nan,np.nan])\n",
    "            # print('Try-except')\n",
    "\n",
    "    # with open(fn_out_pickle, 'wb') as handle:\n",
    "    #     pickle.dump(result, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "######### INPUTS ##########\n",
    "\n",
    "year = 2009\n",
    "\n",
    "######### Global Variables #########\n",
    "\n",
    "## Formatting variables\n",
    "# fn_fmt = '/home/navid/Downloads/{year}_stage4_hourly.nc'\n",
    "fn_fmt = '/storage/coda1/p-rbras6/0/njadidoleslam3/precipitation/stage4/{year}_stage4_hourly.nc'\n",
    "out_pickle_fmt = '/storage/coda1/p-rbras6/0/njadidoleslam3/projects/stochsm/stage4_analysis/events/{year}.pickle'\n",
    "# out_pickle_fmt = '/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/projects/stochsm/stage4_analysis/events/{year}.pickle'\n",
    "\n",
    "\n",
    "start_dt = '{year}-1-1'.format(year = year)\n",
    "end_dt = '{year}-1-1'.format(year = year+1)\n",
    "fn_nc_in = fn_fmt.format(year=year)\n",
    "fn_out_pickle = out_pickle_fmt.format(year=year)\n",
    "# technical variables\n",
    "set_min_mit = 3\n",
    "mit_list = [x for x in range(set_min_mit,12*24, 6)]\n",
    "\n",
    "\n",
    "dt_vec = pd.date_range(start=start_dt, end=end_dt, freq='60min',closed='left')\n",
    "\n",
    "dt_vec_month = dt_vec.month\n",
    "# dt_vec = dt_vec\n",
    "\n",
    "# read dataset row by row, i.e., \n",
    "f = netCDF4.Dataset(fn_nc_in)\n",
    "# f.set_auto_maskandscale(False)\n",
    "# f.set_auto_mask(True)\n",
    "\n",
    "grid_y_list = list(range(881))\n",
    "grid_x_list = list(range(1121))\n",
    "\n",
    "# with open(fn_out_pickle, 'wb') as handle:\n",
    "# grid_y, grid_x = (468, 439)   \n",
    "grid_y, grid_x = (413, 439)   \n",
    "# for grid_y in grid_y_list:\n",
    "data = np.array(f.variables['p01m'][:, grid_y , grid_x].data)\n",
    "lol = []\n",
    "# for grid_x in grid_x_list:\n",
    "gid = int('1{gid_x}{gid_y}'.format(gid_x = str(grid_x).zfill(4), gid_y = str(grid_y).zfill(4)))\n",
    "# events = extract_events1(data)\n",
    "    # lol.append((gid,year,) + events)\n",
    "        # pickle.dump(lol, handle, protocol= pickle.HIGHEST_PROTOCOL)\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}