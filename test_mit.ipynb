{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.features import shapes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create a vectorized raster of the conus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create grid_xy array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "grid_x, grid_y = np.meshgrid(np.arange(1121),np.arange(0,881))\n",
    "grid_xy = grid_x*10**4 + grid_y + 10**8\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## convert raster to shapefile with substituting the pixel values to grid_xy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "mask = None\n",
    "with rasterio.Env():\n",
    "    with rasterio.open('/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/projects/stochsm/data/nws_precip_1day_20210921_conus.tif') as src:\n",
    "        image = src.read(1) # first band\n",
    "        image = grid_xy.astype(np.int32)\n",
    "        results = (\n",
    "        {'properties': {'raster_val': grid_xy.ravel()[i]}, 'geometry': s}\n",
    "        for i, (s, v) in enumerate(\n",
    "            shapes(image,  transform=src.transform)))\n",
    "geoms = list(results)\n",
    "gpd_polygonized_raster  = gp.GeoDataFrame.from_features(geoms)\n",
    "gpd_polygonized_raster.columns = ['geometry', 'grid_xy']\n",
    "gpd_polygonized_raster['grid_xy'] = gpd_polygonized_raster['grid_xy'].astype(np.int64)\n",
    "gpd_polygonized_raster.crs = \"+proj=stere +lat_0=90 +lat_ts=60 +lon_0=-105 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs\"\n",
    "gpd_polygonized_raster.to_file('/storage/coda1/p-rbras6/0/njadidoleslam3/projects/stochsm/data/gis_files/stage4_grid.shp', driver='ESRI Shapefile')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_mit(year):\n",
    "    fn_in = '/storage/coda1/p-rbras6/0/njadidoleslam3/projects/stochsm/stage4_analysis/events/{year}.pickle'.format(year = year)\n",
    "    with open(fn_in, 'rb') as handle:\n",
    "        _mit = pickle.load(handle)\n",
    "    mit_array = np.reshape(np.array(_mit[1:]), (int(len(_mit[1:])/4),4))\n",
    "    mit_array = pd.DataFrame(mit_array)\n",
    "    mit_valid = mit_array.loc[~mit_array[2].isna()]\n",
    "    mit_valid.columns=['grid_xy','min_mit','cv', 'mean_it']\n",
    "    mit_valid['grid_xy'] = mit_valid['grid_xy'].astype(np.int64)\n",
    "\n",
    "    # gpd_polygonized_raster.set_index('grid_xy', inplace=True)\n",
    "    data = gpd_polygonized_raster.join(mit_valid, lsuffix='l')\n",
    "    data_valid = data.loc[~data['min_mit'].isna()]\n",
    "    data_valid['mean_it'] = data_valid['mean_it'].astype(np.float16)\n",
    "    return data_valid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas\n",
    "\n",
    "fn_temp = 'mean_it_{year}.png'\n",
    "for year in range(2000, 2021):\n",
    "    try:\n",
    "\n",
    "        data  = get_mit(year)\n",
    "        cm1 = plt.cm.get_cmap('Reds',10)\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # model_domain.plot(ax=ax, facecolor=\"none\", edgecolor='black', zorder= 5, alpha= 1 )\n",
    "        a = data.plot(ax=ax, column='mean_it', cmap=cm1, vmin = 0, vmax=200)\n",
    "        ax.set_axis_off()\n",
    "        ax.invert_yaxis()\n",
    "        plt.title(str(year), fontsize=25)\n",
    "        cax = fig.add_axes([0.1, 0, 0.8, 0.04])\n",
    "        fig.colorbar( a.collections[0], cax=cax, orientation='horizontal')\n",
    "        cax.set_xlabel('Mean Interarrival Time', fontsize=18)\n",
    "        cax.tick_params(labelsize=16)\n",
    "        # cax.locator_params(nbins=metric_list[met_name]['nbins'] + 1)\n",
    "        cax.tick_params(labelsize=16)\n",
    "        cax.locator_params(nbins=11)\n",
    "        fn_out = os.path.join('/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/projects/stochsm/figures/st4/mean_it',  fn_temp.format(year = year))\n",
    "        fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the result of new algorithm"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "import sys\n",
    "import netCDF4\n",
    "import pickle\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "#######################\n",
    "\n",
    "def extract_events1(p_data):\n",
    "    def storm_def():\n",
    "        def check_mits(mit):\n",
    "            idx = (bin_events  <=-mit)*(bin_events<0)\n",
    "            dry_periods = bin_events[idx]*-1\n",
    "            return np.array([mit, np.std(dry_periods[1:]) / np.mean(dry_periods[1:]),\n",
    "                                np.int32(np.mean(dry_periods[1:]))])\n",
    "\n",
    "        v = (p_data==0)*1\n",
    "        n = v==0\n",
    "        a = ~n\n",
    "        c = np.cumsum(a)\n",
    "        d = np.diff(np.append([0.], c[n]))\n",
    "        v[n] = -d\n",
    "        dry_vec = np.cumsum(v)\n",
    "        bin_events = np.append([1], np.diff(dry_vec))\n",
    "\n",
    "        \n",
    "        mit_dry = []\n",
    "        for mit in mit_list:\n",
    "            _mit = check_mits(mit)\n",
    "            mit_dry.append(_mit)\n",
    "            if ((_mit[1]<1.0) & (len(mit_dry)>1)):\n",
    "                break    # condition satisfied\n",
    "        mit_dry = np.array(mit_dry)\n",
    "        min_mit = calc_min_mit(mit_dry)\n",
    "        \n",
    "        idx = (bin_events  <= -min_mit) * (bin_events < 0)\n",
    "        dry_periods = bin_events[idx]*-1\n",
    "        date_idx = np.where(idx[1:])[0]\n",
    "        event_durations = date_idx[1:] -dry_periods[1:] - date_idx[0:-1]\n",
    "        event_indices = date_idx[0:-1] + event_durations\n",
    "        n_events = len(event_durations)\n",
    "        # storm_def_new(data, mit)\n",
    "\n",
    "        p_totals = [0]*n_events\n",
    "        for i in range(n_events):\n",
    "            p_totals[i] = np.sum(p_data[date_idx[i]:event_indices[i]+1])\n",
    "\n",
    "        \n",
    "        # summary = pd.DataFrame({'dt':dt_vec[date_idx[1:]], 't0':event_durations, 'tb':dry_periods[0:-1], 'intnesity':p_totals/event_durations})\n",
    "        summary = [dt_vec[date_idx[1:]], event_durations, dry_periods[0:-1], p_totals/event_durations]\n",
    "        return min_mit, summary\n",
    "        # return np.array([min_mit, np.std(dry_periods[1:]) / np.mean(dry_periods[1:]), np.int32(np.mean(dry_periods[1:]))])\n",
    "\n",
    "    #######################\n",
    "\n",
    "\n",
    "    def calc_min_mit(p_events):\n",
    "        idx, = np.where((np.diff(np.sign(p_events[:,1]-1)) != 0)*1==1)\n",
    "        if len(idx)==0:\n",
    "            a = np.abs(p_events[:,1]-1)\n",
    "            idx, = np.where(a == a.min())\n",
    "            return p_events[:,0][idx][0]\n",
    "        return (p_events[:,0][idx][0]+p_events[:,0][idx+1][0])/2.0\n",
    "\n",
    "    #######################\n",
    "\n",
    "    result = np.empty((1,1), dtype=object)   \n",
    "    n_data = len(p_data)\n",
    "    # event_metrics = get_events(p_data, set_min_mit)\n",
    "    # %timeit np.sum(p_data < 0)\n",
    "    pos_idx = np.sum((p_data>=0) & (p_data<65535))\n",
    "\n",
    "    # if float(np.sum(neg_idx)/n_data)<0.1:\n",
    "    #     print('No data 1', float(np.sum(p_data < 0)/n_data))\n",
    "    # p_data[p_data<0.5] = 0\n",
    "        \n",
    "    if (float(np.sum(pos_idx)/n_data)==0):\n",
    "        result = np.array([np.nan,np.nan,np.nan])\n",
    "        print('No data 2')\n",
    "    else:\n",
    "        # try:\n",
    "        event_metrics = storm_def()\n",
    "        result = event_metrics\n",
    "        # except:\n",
    "            # result = np.array([np.nan,np.nan,np.nan])\n",
    "            # print('Try-except')\n",
    "\n",
    "    # with open(fn_out_pickle, 'wb') as handle:\n",
    "    #     pickle.dump(result, handle, protocol= pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "######### INPUTS ##########\n",
    "\n",
    "year = 2009\n",
    "\n",
    "######### Global Variables #########\n",
    "\n",
    "## Formatting variables\n",
    "# fn_fmt = '/home/navid/Downloads/{year}_stage4_hourly.nc'\n",
    "fn_fmt = '/storage/coda1/p-rbras6/0/njadidoleslam3/precipitation/stage4/{year}_stage4_hourly.nc'\n",
    "out_pickle_fmt = '/storage/coda1/p-rbras6/0/njadidoleslam3/projects/stochsm/stage4_analysis/events/{year}.pickle'\n",
    "# out_pickle_fmt = '/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/projects/stochsm/stage4_analysis/events/{year}.pickle'\n",
    "\n",
    "\n",
    "start_dt = '{year}-1-1'.format(year = year)\n",
    "end_dt = '{year}-1-1'.format(year = year+1)\n",
    "fn_nc_in = fn_fmt.format(year=year)\n",
    "fn_out_pickle = out_pickle_fmt.format(year=year)\n",
    "# technical variables\n",
    "set_min_mit = 3\n",
    "mit_list = [x for x in range(set_min_mit,12*24, 6)]\n",
    "\n",
    "\n",
    "dt_vec = pd.date_range(start=start_dt, end=end_dt, freq='60min',closed='left')\n",
    "dt_vec = dt_vec.month\n",
    "\n",
    "# read dataset row by row, i.e., \n",
    "f = netCDF4.Dataset(fn_nc_in)\n",
    "# f.set_auto_maskandscale(False)\n",
    "# f.set_auto_mask(True)\n",
    "\n",
    "grid_y_list = list(range(881))\n",
    "grid_x_list = list(range(1121))\n",
    "\n",
    "# with open(fn_out_pickle, 'wb') as handle:\n",
    "    \n",
    "for grid_y in grid_y_list:\n",
    "    data = np.array(f.variables['p01m'][:, grid_y , :].data)\n",
    "    lol = []\n",
    "    for grid_x in grid_x_list:\n",
    "        gid = int('1{gid_x}{gid_y}'.format(gid_x = str(grid_x).zfill(4), gid_y = str(grid_y).zfill(4)))\n",
    "        events = extract_events1(data[:,grid_x])\n",
    "        lol.append((gid,year,) + events)\n",
    "        # pickle.dump(lol, handle, protocol= pickle.HIGHEST_PROTOCOL)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'{year}-1-1'.format(year = str(2000+1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2001-1-1'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pickle\n",
    "data_test = []\n",
    "with open('/storage/coda1/p-rbras6/0/njadidoleslam3/projects/stochsm/stage4_analysis/events/2019.pickle', 'rb') as handle:\n",
    "# with open(filename, 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            data_test.append(pickle.load(handle))\n",
    "    except EOFError:\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "summary = []\n",
    "for i_1 in range(len(data_test)):\n",
    "    for i_2 in range(len(data_test[i_1])):\n",
    "        gid = int(data_test[i_1][i_2][0])\n",
    "        dry_vec = data_test[i_1][i_2][3][2]\n",
    "        summary.append((gid,np.mean(dry_vec)))\n",
    "\n",
    "summary = np.array(summary)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/storage/home/hcoda1/6/njadidoleslam3/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/storage/home/hcoda1/6/njadidoleslam3/venvs/spatialenv/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import geopandas\n",
    "mit_array = pd.DataFrame({'grid_xy':summary[:,0], 'mean_it':summary[:,1]})\n",
    "# mit_valid = mit_array.loc[~mit_array[2].isna()]\n",
    "# mit_valid.columns=['grid_xy','min_mit','cv', 'mean_it']\n",
    "mit_array['grid_xy'] = mit_array['grid_xy'].astype(np.int64)\n",
    "\n",
    "# # gpd_polygonized_raster.set_index('grid_xy', inplace=True)\n",
    "data = gpd_polygonized_raster.join(mit_array, lsuffix='l')\n",
    "# data_valid = data.loc[~data['min_mit'].isna()]\n",
    "data['mean_it'] = data['mean_it'].astype(np.float16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "fn_temp = 'mean_it_{year}.png'\n",
    "cm1 = plt.cm.get_cmap('Reds',10)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "year = 2019\n",
    "# model_domain.plot(ax=ax, facecolor=\"none\", edgecolor='black', zorder= 5, alpha= 1 )\n",
    "a = data.plot(ax=ax, column='mean_it', cmap=cm1, vmin = 0, vmax=200)\n",
    "ax.set_axis_off()\n",
    "ax.invert_yaxis()\n",
    "plt.title(str(year), fontsize=25)\n",
    "cax = fig.add_axes([0.1, 0, 0.8, 0.04])\n",
    "fig.colorbar( a.collections[0], cax=cax, orientation='horizontal')\n",
    "cax.set_xlabel('Mean Interarrival Time', fontsize=18)\n",
    "cax.tick_params(labelsize=16)\n",
    "# cax.locator_params(nbins=metric_list[met_name]['nbins'] + 1)\n",
    "cax.tick_params(labelsize=16)\n",
    "cax.locator_params(nbins=11)\n",
    "fn_out = os.path.join('/storage/home/hcoda1/6/njadidoleslam3/p-rbras6-0/projects/stochsm/trash',  fn_temp.format(year = year))\n",
    "fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "year_list = np.arange(2000,2021)\n",
    "np.random.seed()\n",
    "np.random.shuffle(year_list)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "year_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2020, 2013, 2008, 2017, 2014, 2019, 2015, 2016, 2001, 2003, 2010,\n",
       "       2006, 2011, 2009, 2018, 2012, 2005, 2000, 2002, 2007, 2004])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "year_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2003, 2005, 2012, 2001, 2018, 2010, 2011, 2013, 2004, 2020, 2019,\n",
       "       2009, 2006, 2014, 2000, 2017, 2007, 2008, 2015, 2002, 2016])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "8123462de7ea43a2d996973cbf510d4f29e6ad95875a57645dd7d3660e19a56d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}