{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison of conditional soil moisture statistics\n",
    "## Objectives:\n",
    "- Analyze if GPM rainfall data could provide useful information on the conditional soil moisture\n",
    "- Does GPM capture temporal statistics (e.g., mean and variance) of the observed soil moisture?\n",
    "- How much information does SMAP satellite-based soil moisture contain compared to in situ soil moisture observations?\n",
    "- Validity: Are short-term SMAP data (e.g., 5-6 years) representative of the conditional soil moisture information from in situ observations?\n",
    "- Overall, how good rainfall-driven model soil moisture is compared to SMAP soil moisture with reference to the in situ observations?\n",
    "\n",
    "## Methods:\n",
    "\n",
    "- Use GPM IMERG half-hourly precipitation forcing to simulate soil moisture\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "from datetime import datetime\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='default')\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# import GPM-gage date-matched data\n",
    "# sm_site_list = pd.read_csv('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/ARS_data/SF_stations_.csv')\n",
    "lut_gpm_gage = pd.read_csv('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/GPM/lut_gage_gpm_v1.csv')\n",
    "fn_format = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/ARS_data/1607.zip/SMAP/{st_id}_20130101.csv'\n",
    "##\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# ARS gage data\n",
    "header_list = ['ID','Yr','Mo','Day','Hr','Min','TOY','Tair','PREC_1','PREC_2','SM_5','ST_5','SM_10','ST_10','SM_20','ST_20','SM_50','ST_50']\n",
    "dtypes = 6*['string'] + 12*['float']\n",
    "dtype_dict = dict()\n",
    "for i,col in enumerate(header_list):\n",
    "    dtype_dict[col] = dtypes[i]\n",
    "\n",
    "# import ARS data into sf_gage dictionary\n",
    "# There is a 5 hours offset to make ARS gage data time-zone UTC (found from cross-correlation analysis)\n",
    "sf_gages = dict()\n",
    "\n",
    "for st_id in lut_gpm_gage['st_id']:\n",
    "    st_id = str(st_id)\n",
    "    fn = fn_format.format(st_id=st_id)\n",
    "    sf_gages[st_id] = pd.read_csv(fn, index_col=False, skiprows=2)\n",
    "    sf_gages[st_id].columns = header_list\n",
    "    sf_gages[st_id] = sf_gages[st_id].astype(dtype_dict)\n",
    "    sf_gages[st_id] = sf_gages[st_id].replace([-99, -88], np.nan)\n",
    "    dt = sf_gages[st_id]['Yr'] + '-' + sf_gages[st_id]['Mo'] + '-' + sf_gages[st_id]['Day'] + ' ' + sf_gages[st_id]['Hr'] + ':0' + sf_gages[st_id]['Min']\n",
    "    sf_gages[st_id]['date'] = pd.to_datetime(dt)\n",
    "    sf_gages[st_id]['date'] = sf_gages[st_id]['date'] + pd.DateOffset(hours=5)\n",
    "\n",
    "# GPM data processed with Google Earth Engine (fid_{fid}.csv)\n",
    "# Create a GPM dataset for each pixel over the South Fork watershed\n",
    "# Note: GPM Data are provided with a 30-min interval but values are in mm/hr rainfall rate\n",
    "gage_gpm_fmt = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/GPM/ars/fid_{fid}.csv'\n",
    "gpm_gage = dict()\n",
    "for fid in range(20):\n",
    "    fid = str(fid)\n",
    "    _data = pd.read_csv(gage_gpm_fmt.format(fid=fid), index_col=None)\n",
    "    _data['date'] = pd.to_datetime(_data['date'])\n",
    "    x = _data.set_index('date')\n",
    "    gpm_gage[fid] = x['value'].resample('H').sum()/2\n",
    "    gpm_gage[fid] = gpm_gage[fid].reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Save data in a pickle organized as:\n",
    "gpm_gage_sf = dict()\n",
    "gpm_gage_sf['gpm_gage'] = gpm_gage\n",
    "gpm_gage_sf['sf_gages'] = sf_gages\n",
    "gpm_gage_sf['lut_gpm_gage'] = lut_gpm_gage # Lookup table for gage-GPM \n",
    "\n",
    "# import pickle\n",
    "# with open('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gpm_gage_sf.pickle', 'wb') as handle:\n",
    "#     pickle.dump(gpm_gage_sf, handle, protocol= pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Match the timestamps for both datasets\n",
    "\n",
    "gage_gpm_matched = dict()\n",
    "for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "    fid = str(lut_gpm_gage['FID'][i])\n",
    "    st_id = str(st_id)\n",
    "    gpm_gage_ = gpm_gage[fid]\n",
    "    sf_gages_ = sf_gages[st_id]\n",
    "    gage_gpm_matched[st_id] = pd.merge(gpm_gage_, sf_gages_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Summarize the precipitation totals from GPM and gages\n",
    "gpm_gage_summary = dict()\n",
    "gage_p_sum = []\n",
    "for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "    st_id = str(st_id)\n",
    "    fid = lut_gpm_gage['FID'][i]\n",
    "    gage_p_sum.append(( st_id,\n",
    "                        fid,\n",
    "                        np.nansum(gage_gpm_matched[st_id]['PREC_1'][~gage_gpm_matched[st_id]['PREC_1'].isna()]),    # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['PREC_2'][~gage_gpm_matched[st_id]['PREC_2'].isna()]),    # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['value'][~gage_gpm_matched[st_id]['PREC_1'].isna()]),     # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['value'][~gage_gpm_matched[st_id]['PREC_2'].isna()]) \n",
    "                    ))\n",
    "\n",
    "gage_p_sum = pd.DataFrame(gage_p_sum, columns=['st_id', 'FID', 'sum_PREC_1','sum_PREC_2', 'sum_GPM_1', 'sum_GPM_2'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-scale comparisons (time)\n",
    "## Compare precipitation data from GPM and Gage for three different time scales:\n",
    "- Hourly\n",
    "- Daily\n",
    "- Monthly\n",
    "- Whole record (2013-2020 Note:varying for some stations)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gage data availability plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(16, 10))\n",
    "for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "    st_id = str(st_id)\n",
    "    idx = np.where(~gage_gpm_matched[st_id]['PREC_1'].isna())#~gage_gpm_matched[st_id]['PREC_1'].isna()\n",
    "    y = [i+1]*len(idx[0])\n",
    "    ax.scatter(gage_gpm_matched[st_id]['date'][idx[0]], y, alpha=0.3, c='black', s = 2)\n",
    "ax.tick_params(labelsize = 20)\n",
    "ax.set_yticks([x for x in range(1,21,2)])\n",
    "ax.set_ylabel(r'Station ID', fontsize = 24)\n",
    "# ax.set_xlabel(r'Initial Soil Moisture \\ ($mm$)', fontsize = 24)\n",
    "ax.grid('major',axis='x')\n",
    "fig.savefig('/mnt/d/ubuntu/projects/gatechProjects/StochSM/figures/gage_availability.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Summarize the precipitation totals from GPM and gages\n",
    "gpm_gage_summary = dict()\n",
    "gage_p_sum = []\n",
    "for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "    st_id = str(st_id)\n",
    "    fid = lut_gpm_gage['FID'][i]\n",
    "    gage_p_sum.append(( st_id,\n",
    "                        fid,\n",
    "                        np.nansum(gage_gpm_matched[st_id]['PREC_1'][~gage_gpm_matched[st_id]['PREC_1'].isna()]),    # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['PREC_2'][~gage_gpm_matched[st_id]['PREC_2'].isna()]),    # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['value'][~gage_gpm_matched[st_id]['PREC_1'].isna()]),     # continues \n",
    "                        np.nansum(gage_gpm_matched[st_id]['value'][~gage_gpm_matched[st_id]['PREC_2'].isna()]) \n",
    "                    ))\n",
    "gage_p_sum = pd.DataFrame(gage_p_sum, columns=['st_id', 'FID', 'sum_PREC_1','sum_PREC_2', 'sum_GPM_1', 'sum_GPM_2'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# create precipitation timeseries for each time-scale\n",
    "# Initialize a dictionary with keys for each time-scale\n",
    "gpm_gage_mscale = dict()\n",
    "for tscale in ['H','D', 'M']:\n",
    "        gpm_gage_mscale[tscale] = dict()\n",
    "# Hourly\n",
    "# for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "#         st_id = str(st_id)\n",
    "#         gpm_gage_mscale['H'][st_id] = gage_gpm_matched[st_id]\n",
    "\n",
    "# Daily and Monthly\n",
    "# Accumulate the rainfall totals to each day where there is observation from the gage\n",
    "for tscale in ['H', 'D', 'M']:\n",
    "        for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "                st_id = str(st_id)\n",
    "                gpm_gage_mscale[tscale][st_id] = dict()\n",
    "                for buck_no in ['PREC_1', 'PREC_2']:\n",
    "                        if tscale=='H':\n",
    "                                ts_ = gage_gpm_matched[st_id][['date','value',buck_no]][~gage_gpm_matched[st_id][buck_no].isna()]\n",
    "                                ts_ = ts_.set_index('date')\n",
    "                                # ts_ = ts_[['value','PREC_1','PREC_2']]\n",
    "                                gpm_gage_mscale[tscale][st_id][buck_no] = ts_\n",
    "                        else:        \n",
    "                                ts_ = gage_gpm_matched[st_id][['date','value',buck_no]][~gage_gpm_matched[st_id][buck_no].isna()]\n",
    "                                ts_ = ts_.set_index('date')\n",
    "                                # ts_ = ts_[['value','PREC_1','PREC_2']]\n",
    "                                gpm_gage_mscale[tscale][st_id][buck_no] = ts_.resample(tscale).agg(pd.Series.sum, min_count=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rainfall Analysis\n",
    "## Compare Precipitation totals and analyze rainfall detection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "tscale_meta = {\n",
    "    'H':\n",
    "        {\n",
    "        'ticklabels': ['', '10', '20', '30', '40', ''],\n",
    "        'ticks': [0, 10, 20, 30, 40, 50],\n",
    "        'ax_offset': 2,\n",
    "        'alpha': 0.2\n",
    "        },    \n",
    "    'D':\n",
    "        {\n",
    "        'ticklabels': ['', '20', '40', '60', '80', ''],\n",
    "        'ticks': [0, 20, 40, 60, 80, 100],\n",
    "        'ax_offset': 4,\n",
    "        'alpha': 0.3\n",
    "        },\n",
    "    'M':\n",
    "        {\n",
    "        'ticklabels': ['', '100', '200', '300', '400', ''],\n",
    "        'ticks': [0, 100, 200, 300, 400, 500],\n",
    "        'ax_offset': 10,\n",
    "        'alpha': 0.5\n",
    "        }\n",
    "}\n",
    "for tscale in ['H', 'D', 'M']:        \n",
    "    fig, ax = plt.subplots(3, 5, figsize = (25, 14), sharex = True, sharey = True)\n",
    "    for i, st_id in enumerate(lut_gpm_gage['st_id'][0:15]):\n",
    "        st_id = str(st_id)\n",
    "        i_col = i % 5\n",
    "        i_row = int((i - i_col)/5)\n",
    "        ax[i_row, i_col].scatter(gpm_gage_mscale[tscale][st_id]['PREC_1']['PREC_1'], gpm_gage_mscale[tscale][st_id]['PREC_1']['value'], s = 15, alpha = tscale_meta[tscale]['alpha'], c='red')\n",
    "        ax[i_row, i_col].scatter(gpm_gage_mscale[tscale][st_id]['PREC_2']['PREC_2'], gpm_gage_mscale[tscale][st_id]['PREC_2']['value'], s = 15, alpha = tscale_meta[tscale]['alpha'], c='blue')\n",
    "        ax[i_row, i_col].grid('major')\n",
    "        \n",
    "        lo_lim = min(tscale_meta[tscale]['ticks']) - tscale_meta[tscale]['ax_offset']\n",
    "        up_lim = max(tscale_meta[tscale]['ticks']) - tscale_meta[tscale]['ax_offset']\n",
    "        \n",
    "        ax[i_row, i_col].set_xlim([lo_lim, up_lim])\n",
    "        ax[i_row, i_col].set_ylim([lo_lim, up_lim])\n",
    "\n",
    "        ax[i_row, i_col].set_xticks(tscale_meta[tscale]['ticks'])\n",
    "        ax[i_row, i_col].set_yticks(tscale_meta[tscale]['ticks'])\n",
    "        \n",
    "        ax[i_row, i_col].set_xticklabels(tscale_meta[tscale]['ticklabels'])\n",
    "        ax[i_row, i_col].set_yticklabels(tscale_meta[tscale]['ticklabels'])\n",
    "\n",
    "        ax[i_row, i_col].tick_params(labelsize = 20)\n",
    "    fig.tight_layout()\n",
    "    ax[1, 0].text(-0.2, 0.35, 'GPM (mm)', transform=ax[1, 0].transAxes, fontsize=28, rotation=90)\n",
    "    ax[2, 2].text(.35, -0.15, 'Gage (mm)', transform=ax[2, 2].transAxes, fontsize=28)\n",
    "    \n",
    "    # ax[2, 4].set_axis_off()\n",
    "    fn_out = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/figures/gage_GPM_comparisons/scatter_tscale_{tscale}.jpg'.format(tscale=tscale)\n",
    "    fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "lut_gpm_gage"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>st_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.549998</td>\n",
       "      <td>16070001</td>\n",
       "      <td>SF01</td>\n",
       "      <td>42.542620</td>\n",
       "      <td>-93.589060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070002</td>\n",
       "      <td>SF02</td>\n",
       "      <td>42.469300</td>\n",
       "      <td>-93.565450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070003</td>\n",
       "      <td>SF03</td>\n",
       "      <td>42.452960</td>\n",
       "      <td>-93.567970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.549998</td>\n",
       "      <td>16070004</td>\n",
       "      <td>SF04</td>\n",
       "      <td>42.544590</td>\n",
       "      <td>-93.525270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070005</td>\n",
       "      <td>SF05</td>\n",
       "      <td>42.428570</td>\n",
       "      <td>-93.521580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070006</td>\n",
       "      <td>SF06</td>\n",
       "      <td>42.389600</td>\n",
       "      <td>-93.500130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.549998</td>\n",
       "      <td>16070007</td>\n",
       "      <td>SF07</td>\n",
       "      <td>42.515010</td>\n",
       "      <td>-93.472710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070008</td>\n",
       "      <td>SF08</td>\n",
       "      <td>42.484630</td>\n",
       "      <td>-93.441490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070009</td>\n",
       "      <td>SF09</td>\n",
       "      <td>42.445560</td>\n",
       "      <td>-93.444050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070010</td>\n",
       "      <td>SF10</td>\n",
       "      <td>42.379370</td>\n",
       "      <td>-93.402930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-93.349999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070011</td>\n",
       "      <td>SF11</td>\n",
       "      <td>42.429750</td>\n",
       "      <td>-93.365960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>-93.349999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070012</td>\n",
       "      <td>SF12</td>\n",
       "      <td>42.341400</td>\n",
       "      <td>-93.334220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>-93.349999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070013</td>\n",
       "      <td>SF13</td>\n",
       "      <td>42.403180</td>\n",
       "      <td>-93.309710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>-93.249999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070014</td>\n",
       "      <td>SF14</td>\n",
       "      <td>42.328310</td>\n",
       "      <td>-93.254860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>-93.249999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070015</td>\n",
       "      <td>SF15</td>\n",
       "      <td>42.420340</td>\n",
       "      <td>-93.220770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070016</td>\n",
       "      <td>NA02</td>\n",
       "      <td>42.304850</td>\n",
       "      <td>-93.483616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>-93.449999</td>\n",
       "      <td>42.349998</td>\n",
       "      <td>16070017</td>\n",
       "      <td>NA03</td>\n",
       "      <td>42.398868</td>\n",
       "      <td>-93.444281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>-93.549999</td>\n",
       "      <td>42.249998</td>\n",
       "      <td>16070018</td>\n",
       "      <td>NA01</td>\n",
       "      <td>42.297846</td>\n",
       "      <td>-93.520643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>-93.349999</td>\n",
       "      <td>42.649998</td>\n",
       "      <td>16070019</td>\n",
       "      <td>NA04</td>\n",
       "      <td>42.637269</td>\n",
       "      <td>-93.341192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>-93.249999</td>\n",
       "      <td>42.449998</td>\n",
       "      <td>16070020</td>\n",
       "      <td>NA05</td>\n",
       "      <td>42.451260</td>\n",
       "      <td>-93.232442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID          X          Y     st_id    ID   Latitude  Longitude\n",
       "0     4 -93.549999  42.549998  16070001  SF01  42.542620 -93.589060\n",
       "1     8 -93.549999  42.449998  16070002  SF02  42.469300 -93.565450\n",
       "2     8 -93.549999  42.449998  16070003  SF03  42.452960 -93.567970\n",
       "3     4 -93.549999  42.549998  16070004  SF04  42.544590 -93.525270\n",
       "4     8 -93.549999  42.449998  16070005  SF05  42.428570 -93.521580\n",
       "5    12 -93.549999  42.349998  16070006  SF06  42.389600 -93.500130\n",
       "6     5 -93.449999  42.549998  16070007  SF07  42.515010 -93.472710\n",
       "7     9 -93.449999  42.449998  16070008  SF08  42.484630 -93.441490\n",
       "8     9 -93.449999  42.449998  16070009  SF09  42.445560 -93.444050\n",
       "9    13 -93.449999  42.349998  16070010  SF10  42.379370 -93.402930\n",
       "10   10 -93.349999  42.449998  16070011  SF11  42.429750 -93.365960\n",
       "11   14 -93.349999  42.349998  16070012  SF12  42.341400 -93.334220\n",
       "12   10 -93.349999  42.449998  16070013  SF13  42.403180 -93.309710\n",
       "13   15 -93.249999  42.349998  16070014  SF14  42.328310 -93.254860\n",
       "14   11 -93.249999  42.449998  16070015  SF15  42.420340 -93.220770\n",
       "15   13 -93.449999  42.349998  16070016  NA02  42.304850 -93.483616\n",
       "16   13 -93.449999  42.349998  16070017  NA03  42.398868 -93.444281\n",
       "17   16 -93.549999  42.249998  16070018  NA01  42.297846 -93.520643\n",
       "18    2 -93.349999  42.649998  16070019  NA04  42.637269 -93.341192\n",
       "19   11 -93.249999  42.449998  16070020  NA05  42.451260 -93.232442"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "\n",
    "# Rainfall totals summary table\n",
    "\n",
    "\n",
    "# gage_p_sum = []\n",
    "# for i, st_id in enumerate(lut_gpm_gage['st_id']):\n",
    "#     fid = str(lut_gpm_gage['FID'][i])\n",
    "#     st_id = str(st_id)\n",
    "#     gage_p_sum.append((st_id, np.nansum(sf_gages[st_id]['PREC_1']), np.nansum(sf_gages[st_id]['PREC_2']), np.nansum(gpm_gage[fid]['value'])))\n",
    "\n",
    "\n",
    "\n",
    "# GPM has less NaN values than gages -> use dates from gage \n",
    "# gage_p_sum = pd.DataFrame(gage_p_sum, columns=['st_id', 'sum_PREC_1','sum_PREC_2', 'sum_GPM'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# test plots for soil moisture simulations vs observations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pickle\n",
    "with open('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/ARS_data/gpm_gage_sm.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "\n",
    "with open('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gpm_gage_sf.pickle', 'rb') as handle:\n",
    "    gpm_gage_sf = pickle.load(handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "s_props = pd.read_csv('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/sm_gages_w_SProps.csv')\n",
    "prod_list = dict({\n",
    "                'tscales': ['H'],\n",
    "                'scale_f': 1,\n",
    "                'dt_col': 'date',\n",
    "                'p_cols': ['value', 'PREC_1', 'PREC_2'],\n",
    "                'p_thres': 0,\n",
    "                'alias': ['gpm', 'gage1', 'gage2']\n",
    "                 })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "for i, st_id in enumerate(gpm_gage_sf['lut_gpm_gage']['st_id'][0:15]):\n",
    "    fig, ax = plt.subplots( figsize = (16, 8))\n",
    "    st_id = str(st_id)\n",
    "    \n",
    "    idx = np.where(s_props['name']=='ARS' + st_id)\n",
    "    \n",
    "    if len(idx[0]) ==0:\n",
    "        idx = 61 \n",
    "    else:\n",
    "        idx = idx[0][0]\n",
    "\n",
    "    theta_s = s_props['theta_s'][idx] # cm3/cm3\n",
    "    theta_s_mm = theta_s * 1000 # cm^3/cm^3 to mm in a reference one-meter soil column\n",
    "    # theta_s_mm*theta_s\n",
    "\n",
    "    i_col = i % 5\n",
    "    i_row = int((i - i_col)/5)\n",
    "    # ax.plot(results[st_id]['value']['res_p'][:,3], results[st_id]['value']['res_p'][:,1],  c='red')\n",
    "    # ax.plot(results[st_id]['PREC_1']['res_p'][:,3], results[st_id]['PREC_1']['res_p'][:,1], c='blue')\n",
    "    theta_s_sensor = np.percentile(results[st_id]['SM']['SM_avg'], 97)\n",
    "    ax.plot(results[st_id]['PREC_2']['res_p'][:,3], results[st_id]['PREC_2']['res_p'][:,1]*theta_s_sensor/theta_s, c='green')\n",
    "    ax.plot(results[st_id]['SM']['date'], results[st_id]['SM']['SM_avg'],   c='red')\n",
    "    # ax[i_row, i_col].plot(gpm_gage_mscale[tscale][st_id]['PREC_2']['PREC_2'], gpm_gage_mscale[tscale][st_id]['PREC_2']['value'], s = 15, alpha = tscale_meta[tscale]['alpha'], c='blue')\n",
    "    # ax[i_row, i_col].grid('major')\n",
    "    \n",
    "    # lo_lim = min(tscale_meta[tscale]['ticks']) - tscale_meta[tscale]['ax_offset']\n",
    "    # up_lim = max(tscale_meta[tscale]['ticks']) - tscale_meta[tscale]['ax_offset']\n",
    "    \n",
    "    # ax[i_row, i_col].set_xlim([lo_lim, up_lim])\n",
    "    ax.set_ylim([-0.1, 0.6])\n",
    "\n",
    "    # ax[i_row, i_col].set_xticks(tscale_meta[tscale]['ticks'])\n",
    "    # ax[i_row, i_col].set_yticks(tscale_meta[tscale]['ticks'])\n",
    "    \n",
    "    # ax[i_row, i_col].set_xticklabels(tscale_meta[tscale]['ticklabels'])\n",
    "    # ax[i_row, i_col].set_yticklabels(tscale_meta[tscale]['ticklabels'])\n",
    "    # ax.set_xlim([datetime(2015,5,1), datetime(2015,7,1)])\n",
    "    ax.tick_params(labelsize = 20)\n",
    "    fig.tight_layout()\n",
    "    # ax[1, 0].text(-0.2, 0.35, 'GPM (mm)', transform=ax[1, 0].transAxes, fontsize=28, rotation=90)\n",
    "    # ax[2, 2].text(.35, -0.15, 'Gage (mm)', transform=ax[2, 2].transAxes, fontsize=28)\n",
    "\n",
    "    # input()\n",
    "    fn_out = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/figures/gage_GPM_comparisons/test_sm/{st_id}.jpg'.format(st_id=st_id)\n",
    "    fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "out_fn_format = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/hydrovise_data/sm/{year}/{prod}/{st_id}.csv'\n",
    "\n",
    "for i, st_id in enumerate(gpm_gage_sf['lut_gpm_gage']['st_id'][0:15]):\n",
    "    st_id = str(st_id)\n",
    "    \n",
    "    idx = np.where(s_props['name']=='ARS' + st_id)\n",
    "    \n",
    "    if len(idx[0]) ==0:\n",
    "        idx = 61 \n",
    "    else:\n",
    "        idx = idx[0][0]\n",
    "\n",
    "    theta_s = s_props['theta_s'][idx] # cm3/cm3\n",
    "    theta_s_mm = theta_s * 1000 # cm^3/cm^3 to mm in a reference one-meter soil column\n",
    "\n",
    "    theta_s_sensor = np.percentile(results[st_id]['SM']['SM_avg'], 97)\n",
    "    sm_obs = pd.DataFrame({'date': results[st_id]['SM']['date'], 'SM':results[st_id]['SM']['SM_avg']})\n",
    "    sm_obs['date'] = pd.to_datetime(sm_obs['date'])\n",
    "    sm_obs['SM'] = sm_obs['SM'].astype('float')\n",
    "    for year in range(2013,2021):\n",
    "                idx = sm_obs['date'].dt.year == year\n",
    "                subset_obs = sm_obs.loc[idx]\n",
    "                fn_out = out_fn_format.format(year = str(year), prod = 'sm_obs', st_id= st_id)\n",
    "                [out_path, _]  = os.path.split(fn_out)\n",
    "                if not os.path.exists(out_path):\n",
    "                    os.makedirs(out_path)\n",
    "                subset_obs.to_csv(fn_out,index=False,float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    for i, p_col in enumerate(prod_list['p_cols']):\n",
    "        date_    = results[st_id][p_col]['res_p'][:,3]\n",
    "        sm_      = results[st_id][p_col]['res_p'][:,1]*theta_s_sensor/theta_s\n",
    "        df_sim   =  pd.DataFrame({'date':date_, 'SM':sm_} ,dtype = object)\n",
    "        df_sim['date'] = pd.to_datetime(df_sim['date'])\n",
    "        df_sim['SM'] = df_sim['SM'].astype('float')\n",
    "\n",
    "        for year in range(2013,2021):\n",
    "            idx = df_sim['date'].dt.year == year\n",
    "            subset = df_sim.loc[idx]\n",
    "            fn_out = out_fn_format.format(year = str(year), prod = prod_list['alias'][i], st_id= st_id)\n",
    "            [out_path, _]  = os.path.split(fn_out)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            \n",
    "            subset.to_csv(fn_out,index=False, float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot metrics\n",
    "\n",
    "PDF of the yearly-based metrics for all gages for:\n",
    "gage 1\n",
    "gage 2\n",
    "gpm\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "metric_list = { 'correlationcoefficient':   {'max':1,       'min':-0.1, 'label': 'Cor. Coeff. [-]',               'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                # 'spearmann_corr':           {'max':1,       'min':-1,   'label': 'Spearman Cor. Coeff. [-]',    'bw':.04,   'nbins':10, 'cmap':'YlOrRd'},\n",
    "                'kge':                      {'max':1,       'min':-0.1, 'label': 'KGE [-]',                     'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                # 'kge_non_parametric':       {'max':1,       'min':-1,   'label': 'Non-Param. KGE [-]',          'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                'rmse':                     {'max':0.20,    'min':0,    'label': 'RMSE [$cm^3/cm^3$]',          'bw':0.01,  'nbins':10, 'cmap':'YlOrRd'}, \n",
    "                'rrmse':                    {'max':1.0,     'min':0,    'label': 'Rel. RMSE [$cm^3/cm^3$]',     'bw':0.01,  'nbins':10, 'cmap':'YlOrRd'},\n",
    "                'mae':                      {'max':0.16,    'min':0,    'label': 'MAE [$cm^3/cm^3$]',           'bw':0.01,  'nbins':8, 'cmap':'YlOrRd'}, \n",
    "                'bias':                     {'max':0.2,     'min':-0.2, 'label': 'Bias [$cm^3/cm^3$]',          'bw':0.01,  'nbins':8, 'cmap':'RdBu'}}\n",
    "combs = [('gage1', 'SM'),\n",
    " ('gage2', 'SM'),\n",
    "('gpm', 'SM')]\n",
    "def genTitle(type1, type2):\n",
    "\n",
    "    type1 = type1.replace('gage1', \"Gage 1\").replace('gage2', \"Gage 2\").replace('gpm', \"GPM\")\n",
    "    type2 = type2.upper().replace('SM', \"Sensor Average\")\n",
    "    return type1 + ' vs. ' + type2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "metrics = pd.read_csv('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/metrics/SM_metrics.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "combs = [('gage1', 'SM'),\n",
    " ('gage2', 'SM'),\n",
    "('gpm', 'SM')]\n",
    "\n",
    "ln_colors = ['c','r','g', 'b', 'm', 'y', 'k', 'w']\n",
    "\n",
    "fig_path_fmt = r'/mnt/d/ubuntu/projects/gatechProjects/StochSM/figures/metrics/'\n",
    "fn_temp = '{met_name}.jpg'\n",
    "n_y=2\n",
    "n_x=1\n",
    "n_met = 3\n",
    "fig, ax = plt.subplots(n_met,n_x*n_y, figsize=(20, 15))\n",
    "axis_font = {'fontname':'Arial', 'size':'20'}\n",
    "# j=0    \n",
    "for i, met_name in enumerate(list(metric_list.keys())):\n",
    "    cm1 = plt.cm.get_cmap(metric_list[met_name]['cmap'], metric_list[met_name]['nbins']-0)\n",
    "    for j, comb in enumerate(combs):\n",
    "        type1, type2 = comb\n",
    "        comb_name = type1 + '_' + type2\n",
    "        title_str = genTitle(type1, type2)\n",
    "        i_x, i_y = (int(i%n_met), int(i/(3)))\n",
    "        \n",
    "        # if i_y==0:\n",
    "        ax[i_x, i_y].set_ylabel(r\"[\\%]\", **axis_font)\n",
    "        col = ln_colors[j]\n",
    "        ix = metrics['prod']==comb_name\n",
    "        data = metrics[ix]\n",
    "        \n",
    "        kde = KernelDensity(bandwidth=metric_list[met_name]['bw'], kernel='gaussian')\n",
    "        x = data[met_name].values\n",
    "        kde.fit(x[~np.isnan(x), None])\n",
    "        x_d = np.linspace(metric_list[met_name]['min'], metric_list[met_name]['max'], 100)\n",
    "        logprob = kde.score_samples(x_d[:, None])\n",
    "        label_str = genTitle(type1, type2)\n",
    "        ax[i_x, i_y].plot(x_d, np.exp(logprob), linewidth=3, label = label_str, c=col )\n",
    "        ax[i_x, i_y].axvline(x = np.median(x[~np.isnan(x), None]),linewidth=3, color=col)\n",
    "    ax[i_x,  i_y].set_xlabel(str(metric_list[met_name]['label']),fontsize=20 )\n",
    "    ax[i_x, i_y].tick_params(labelsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(fontsize=16,loc='lower center', bbox_to_anchor=(-0.02, 3.5),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "out_path = fig_path_fmt\n",
    "if os.path.exists(out_path)==False:\n",
    "    os.makedirs(out_path)\n",
    "fn_out = os.path.join(out_path, 'all_metrics.jpg')\n",
    "fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# event-based"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pickle\n",
    "with open('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/ARS_data/gpm_gage_sm_event_based.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "out_fn_format = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/hydrovise_data/sm_event_based/{year}/{prod}/{st_id}.csv'\n",
    "\n",
    "for i, st_id in enumerate(gpm_gage_sf['lut_gpm_gage']['st_id'][0:15]):\n",
    "    st_id = str(st_id)\n",
    "    \n",
    "    idx = np.where(s_props['name']=='ARS' + st_id)\n",
    "    \n",
    "    if len(idx[0]) ==0:\n",
    "        idx = 61 \n",
    "    else:\n",
    "        idx = idx[0][0]\n",
    "\n",
    "    theta_s = s_props['theta_s'][idx] # cm3/cm3\n",
    "    theta_s_mm = theta_s * 1000 # cm^3/cm^3 to mm in a reference one-meter soil column\n",
    "\n",
    "    theta_s_sensor = np.percentile(results[st_id]['SM']['SM_avg'], 97)\n",
    "    sm_obs = pd.DataFrame({'date': results[st_id]['SM']['date'], 'SM':results[st_id]['SM']['SM_avg']})\n",
    "    sm_obs['date'] = pd.to_datetime(sm_obs['date'])\n",
    "    sm_obs['SM'] = sm_obs['SM'].astype('float')\n",
    "    for year in range(2013,2021):\n",
    "                idx = sm_obs['date'].dt.year == year\n",
    "                subset_obs = sm_obs.loc[idx]\n",
    "                fn_out = out_fn_format.format(year = str(year), prod = 'sm_obs', st_id= st_id)\n",
    "                [out_path, _]  = os.path.split(fn_out)\n",
    "                if not os.path.exists(out_path):\n",
    "                    os.makedirs(out_path)\n",
    "                subset_obs.to_csv(fn_out,index=False,float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    for i, p_col in enumerate(prod_list['p_cols']):\n",
    "        date_    = results[st_id][p_col]['res_p'][:,3]\n",
    "        sm_      = results[st_id][p_col]['res_p'][:,1]*theta_s_sensor/theta_s\n",
    "        df_sim   =  pd.DataFrame({'date':date_, 'SM':sm_} ,dtype = object)\n",
    "        df_sim['date'] = pd.to_datetime(df_sim['date'])\n",
    "        df_sim['SM'] = df_sim['SM'].astype('float')\n",
    "\n",
    "        for year in range(2013,2021):\n",
    "            idx = df_sim['date'].dt.year == year\n",
    "            subset = df_sim.loc[idx]\n",
    "            fn_out = out_fn_format.format(year = str(year), prod = prod_list['alias'][i], st_id= st_id)\n",
    "            [out_path, _]  = os.path.split(fn_out)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            \n",
    "            subset.to_csv(fn_out,index=False, float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "metric_list = { 'correlationcoefficient':   {'max':1,       'min':-0.1, 'label': 'Cor. Coeff. [-]',               'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                # 'spearmann_corr':           {'max':1,       'min':-1,   'label': 'Spearman Cor. Coeff. [-]',    'bw':.04,   'nbins':10, 'cmap':'YlOrRd'},\n",
    "                'kge':                      {'max':1,       'min':-0.1, 'label': 'KGE [-]',                     'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                # 'kge_non_parametric':       {'max':1,       'min':-1,   'label': 'Non-Param. KGE [-]',          'bw':.04,   'nbins':11, 'cmap':'YlOrRd'},\n",
    "                'rmse':                     {'max':0.20,    'min':0,    'label': 'RMSE [$cm^3/cm^3$]',          'bw':0.01,  'nbins':10, 'cmap':'YlOrRd'}, \n",
    "                'rrmse':                    {'max':1.0,     'min':0,    'label': 'Rel. RMSE [$cm^3/cm^3$]',     'bw':0.01,  'nbins':10, 'cmap':'YlOrRd'},\n",
    "                'mae':                      {'max':0.16,    'min':0,    'label': 'MAE [$cm^3/cm^3$]',           'bw':0.01,  'nbins':8, 'cmap':'YlOrRd'}, \n",
    "                'bias':                     {'max':0.2,     'min':-0.2, 'label': 'Bias [$cm^3/cm^3$]',          'bw':0.01,  'nbins':8, 'cmap':'RdBu'}}\n",
    "combs = [('gage1', 'SM'),\n",
    " ('gage2', 'SM'),\n",
    "('gpm', 'SM')]\n",
    "def genTitle(type1, type2):\n",
    "\n",
    "    type1 = type1.replace('gage1', \"Gage 1\").replace('gage2', \"Gage 2\").replace('gpm', \"GPM\")\n",
    "    type2 = type2.upper().replace('SM', \"Sensor Average\")\n",
    "    return type1 + ' vs. ' + type2\n",
    "\n",
    "metrics = pd.read_csv('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/metrics/SM_metrics_event_based.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "combs = [('gage1', 'SM'),\n",
    " ('gage2', 'SM'),\n",
    "('gpm', 'SM')]\n",
    "\n",
    "ln_colors = ['c','r','g', 'b', 'm', 'y', 'k', 'w']\n",
    "\n",
    "fig_path_fmt = r'/mnt/d/ubuntu/projects/gatechProjects/StochSM/figures/metrics/'\n",
    "fn_temp = '{met_name}.jpg'\n",
    "n_y=2\n",
    "n_x=1\n",
    "n_met = 3\n",
    "fig, ax = plt.subplots(n_met,n_x*n_y, figsize=(20, 15))\n",
    "axis_font = {'fontname':'Arial', 'size':'20'}\n",
    "# j=0    \n",
    "for i, met_name in enumerate(list(metric_list.keys())):\n",
    "    cm1 = plt.cm.get_cmap(metric_list[met_name]['cmap'], metric_list[met_name]['nbins']-0)\n",
    "    for j, comb in enumerate(combs):\n",
    "        type1, type2 = comb\n",
    "        comb_name = type1 + '_' + type2\n",
    "        title_str = genTitle(type1, type2)\n",
    "        i_x, i_y = (int(i%n_met), int(i/(3)))\n",
    "        \n",
    "        # if i_y==0:\n",
    "        ax[i_x, i_y].set_ylabel(r\"[\\%]\", **axis_font)\n",
    "        col = ln_colors[j]\n",
    "        ix = metrics['prod']==comb_name\n",
    "        data = metrics[ix]\n",
    "        \n",
    "        kde = KernelDensity(bandwidth=metric_list[met_name]['bw'], kernel='gaussian')\n",
    "        x = data[met_name].values\n",
    "        kde.fit(x[~np.isnan(x), None])\n",
    "        x_d = np.linspace(metric_list[met_name]['min'], metric_list[met_name]['max'], 100)\n",
    "        logprob = kde.score_samples(x_d[:, None])\n",
    "        label_str = genTitle(type1, type2)\n",
    "        ax[i_x, i_y].plot(x_d, np.exp(logprob), linewidth=3, label = label_str, c=col )\n",
    "        ax[i_x, i_y].axvline(x = np.median(x[~np.isnan(x), None]),linewidth=3, color=col)\n",
    "    ax[i_x,  i_y].set_xlabel(str(metric_list[met_name]['label']),fontsize=20 )\n",
    "    ax[i_x, i_y].tick_params(labelsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(fontsize=16,loc='lower center', bbox_to_anchor=(-0.02, 3.5),\n",
    "          fancybox=True, shadow=True, ncol=5)\n",
    "\n",
    "out_path = fig_path_fmt\n",
    "if os.path.exists(out_path)==False:\n",
    "    os.makedirs(out_path)\n",
    "fn_out = os.path.join(out_path, 'all_metrics_event_based.jpg')\n",
    "fig.savefig(fn_out, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "with open('/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/gages/ARS_data/gpm_gage_sm_event_based.pickle', 'rb') as handle:\n",
    "    results = pickle.load(handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "out_fn_format = '/mnt/d/ubuntu/projects/gatechProjects/StochSM/data/hydrovise_data/sm_event_based/{year}/{prod}/{st_id}.csv'\n",
    "\n",
    "for i, st_id in enumerate(gpm_gage_sf['lut_gpm_gage']['st_id'][0:15]):\n",
    "    st_id = str(st_id)\n",
    "    \n",
    "    idx = np.where(s_props['name']=='ARS' + st_id)\n",
    "    \n",
    "    if len(idx[0]) ==0:\n",
    "        idx = 61 \n",
    "    else:\n",
    "        idx = idx[0][0]\n",
    "\n",
    "    theta_s = s_props['theta_s'][idx] # cm3/cm3\n",
    "    theta_s_mm = theta_s * 1000 # cm^3/cm^3 to mm in a reference one-meter soil column\n",
    "\n",
    "    theta_s_sensor = np.percentile(results[st_id]['SM']['SM_avg'], 97)\n",
    "    sm_obs = pd.DataFrame({'date': results[st_id]['SM']['date'], 'SM':results[st_id]['SM']['SM_avg']})\n",
    "    sm_obs['date'] = pd.to_datetime(sm_obs['date'])\n",
    "    sm_obs['SM'] = sm_obs['SM'].astype('float')\n",
    "    for year in range(2013,2021):\n",
    "                idx = sm_obs['date'].dt.year == year\n",
    "                subset_obs = sm_obs.loc[idx]\n",
    "                fn_out = out_fn_format.format(year = str(year), prod = 'sm_obs', st_id= st_id)\n",
    "                [out_path, _]  = os.path.split(fn_out)\n",
    "                if not os.path.exists(out_path):\n",
    "                    os.makedirs(out_path)\n",
    "                subset_obs.to_csv(fn_out,index=False,float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n",
    "    for i, p_col in enumerate(prod_list['p_cols']):\n",
    "        date_    = results[st_id][p_col]['res_p'][:,3]\n",
    "        sm_      = results[st_id][p_col]['res_p'][:,1]*theta_s_sensor/theta_s\n",
    "        df_sim   =  pd.DataFrame({'date':date_, 'SM':sm_} ,dtype = object)\n",
    "        df_sim['date'] = pd.to_datetime(df_sim['date'])\n",
    "        df_sim['SM'] = df_sim['SM'].astype('float')\n",
    "\n",
    "        for year in range(2013,2021):\n",
    "            idx = df_sim['date'].dt.year == year\n",
    "            subset = df_sim.loc[idx]\n",
    "            fn_out = out_fn_format.format(year = str(year), prod = prod_list['alias'][i], st_id= st_id)\n",
    "            [out_path, _]  = os.path.split(fn_out)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            \n",
    "            subset.to_csv(fn_out,index=False, float_format='%.4f', date_format='%Y-%m-%d %H:%M')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('geo_vis': conda)"
  },
  "interpreter": {
   "hash": "5706a8aecc5f39dbd0f2696bc457f94f55cd41c3c92fc63ef832b4f1bafc0040"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}